# FastMCP_RecSys
This is a CLIP-Based Fashion Recommender with MCP. 

### ðŸ“Œ Sample Components for UI
1. Image upload
2. Submit button
3. Display clothing tags + recommendations

# Mockup
A user uploads a clothing image â†’ YOLO detects clothing â†’ CLIP encodes â†’ Recommend similar

<img width="463" alt="Screenshot 2025-04-26 at 10 26 13â€¯AM" src="https://github.com/user-attachments/assets/93c0a75b-4ed1-4fa1-b25d-5137b8eb6af0" />


# Folder Structure
```
/project-root
â”‚
â”œâ”€â”€ /backend
â”‚   â”œâ”€â”€ Dockerfile            
â”‚   â”œâ”€â”€ /app
â”‚   â”œâ”€â”€ /aws
â”‚   â”‚   â”‚   â””â”€â”€ rekognition_wrapper.py         # AWS Rekognition logic
â”‚   â”‚   â”œâ”€â”€ /utils
â”‚   â”‚   â”‚   â””â”€â”€ image_utils.py                 # Bounding box crop utils
â”‚   â”‚   â”œâ”€â”€ /controllers
â”‚   â”‚   â”‚   â””â”€â”€ clothing_detector.py           # Coordinates Rekognition + cropping
â”‚   â”‚   â”œâ”€â”€ /tests
â”‚   â”‚   â”‚   â”œâ”€â”€ test_rekognition_wrapper.py
â”‚   â”‚   â”‚   â””â”€â”€
â”‚   â”‚   â”œâ”€â”€ server.py                    # FastAPI app code
â”‚   â”‚   â”œâ”€â”€ /routes
â”‚   â”‚   â”‚   â””â”€â”€ clothing_routes.py
â”‚   â”‚   â”œâ”€â”€ /controllers
â”‚   â”‚   â”‚   â”œâ”€â”€ clothing_controller.py
â”‚   â”‚   â”‚   â”œâ”€â”€ clothing_tagging.py
â”‚   â”‚   â”‚   â””â”€â”€ tag_extractor.py         # Pending: define core CLIP functionality
â”‚   â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â”‚   â””â”€â”€ clothing_schemas.py
â”‚   â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”‚   â”œâ”€â”€ tag_list_en.py           $ Tool for mapping: https://jsoncrack.com/editor
â”‚   â”‚   â”‚   â”œâ”€â”€ database.py       
â”‚   â”‚   â”‚   â”œâ”€â”€ settings.py       
â”‚   â”‚   â”‚   â””â”€â”€ api_keys.py     
â”‚   â”‚   â””â”€â”€ requirements.txt      
â”‚   â””â”€â”€ .env                      
â”‚                      
â”œâ”€â”€ /frontend 
â”‚   â”œâ”€â”€ Dockerfile        
â”‚   â”œâ”€â”€ package.json              
â”‚   â”œâ”€â”€ package-lock.json         
â”‚   â”œâ”€â”€ /public
â”‚   â”‚   â””â”€â”€ index.html            
â”‚   â”œâ”€â”€ /src
â”‚   â”‚   â”œâ”€â”€ /components            
â”‚   â”‚   â”‚   â”œâ”€â”€ ImageUpload.jsx    
â”‚   â”‚   â”‚   â”œâ”€â”€ DetectedTags.jsx   
â”‚   â”‚   â”‚   â””â”€â”€ Recommendations.jsx 
â”‚   â”‚   â”œâ”€â”€ /utils
â”‚   â”‚   â”‚   â””â”€â”€ api.js             
â”‚   â”‚   â”œâ”€â”€ App.js                    # Main React component
â”‚   â”‚   â”œâ”€â”€ index.js
â”‚   â”‚   â”œâ”€â”€ index.css            
â”‚   â”‚   â”œâ”€â”€ tailwind.config.js        
â”‚   â”‚   â””â”€â”€ postcss.config.js                    
â”‚   â””â”€â”€ .env                                
â”œâ”€â”€ docker-compose.yml                     
â””â”€â”€ README.md 
```

## Quick Start Guide
### Step 1: Clone the GitHub Project
### Step 2: Set Up the Python Environment
```
python -m venv venv
source venv/bin/activate  # On macOS or Linux
venv\Scripts\activate     # On Windows
```
### Step 3: Install Dependencies
```
pip install -r requirements.txt
```
### Step 4: Start the FastAPI Server (Backend)
```
uvicorn backend.app.server:app --reload
```
Once the server is running and the database is connected, you should see the following message in the console:
```
Database connected
INFO:     Application startup complete.
```
<img width="750" alt="Screenshot 2025-04-25 at 1 15 45â€¯AM" src="https://github.com/user-attachments/assets/7f3fc403-fb33-4107-a00c-61796a48ecec" />

### Step 5: Install Dependencies
Database connected
INFO:     Application startup complete.
```
npm install
```
### Step 6: Start the Development Server (Frontend)
```
npm start
```
Once running, the server logs a confirmation and opens the app in your browser: [http://localhost:3000/](http://localhost:3000/)

<img width="372" alt="Screenshot 2025-04-25 at 9 08 50â€¯PM" src="https://github.com/user-attachments/assets/794a6dba-9fbb-40f1-9e57-c5c2e2af1013" />

# Whatâ€™s completed so far:
1. FastAPI server is up and running (24 Apr)
2. Database connection is set up (24 Apr)
3. Backend architecture is functional (24 Apr)
4. Basic front-end UI for uploading picture (25 Apr)
## 5. Mock Testing for AWS Rekognition -> bounding box (15 May)
```
PYTHONPATH=. pytest backend/app/tests/test_rekognition_wrapper.py
```
<img width="1067" alt="Screenshot 2025-05-20 at 4 58 14â€¯PM" src="https://github.com/user-attachments/assets/7a25a92d-2aca-42a8-abdd-194dd9d2e8a5" />

- Tested Rekognition integration logic independently using a mock â†’ verified it correctly extracts bounding boxes only when labels match the garment set
- Confirmed the folder structure and PYTHONPATH=. works smoothly with pytest from root

## 6. Mock Testing for AWS Rekognition -> CLIP (20 May)
```
PYTHONPATH=. pytest backend/app/tests/test_clothing_tagging.py
```
<img width="1062" alt="Screenshot 2025-05-21 at 9 25 33â€¯AM" src="https://github.com/user-attachments/assets/6c64b658-3414-4115-9e20-520132605cab" />

- Detecting garments using AWS Rekognition 

- Cropping the image around detected bounding boxes

- Tagging the cropped image using CLIP

## 7. Mock Testing for full image tagging pipeline (Image bytes â†’ AWS Rekognition (detect garments) â†’ Crop images â†’ CLIP (predict tags)
```
PYTHONPATH=. pytest backend/app/tests/test_clothing_tagging.py
```
<img width="1072" alt="Screenshot 2025-05-21 at 11 19 47â€¯AM" src="https://github.com/user-attachments/assets/b41f07f4-7926-44a3-8b64-34fe3c6ef049" />

- detect_garments: simulates AWS Rekognition returning one bounding box: {"Left": 0.1, "Top": 0.1, "Width": 0.5, "Height": 0.5}
- crop_by_bounding_box: simulates the cropping step returning a dummy "cropped_image" object
- get_tags_from_clip: simulates CLIP returning a list of tags: ["T-shirt", "Cotton", "Casual"]

Next Step:
1. Evaluate CLIPâ€™s tagging accuracy on sample clothing images
2. Fine-tune the tagging system for better recommendations
3. Test the backend integration with real-time user data
4. Set up monitoring for model performance
5. Front-end demo
